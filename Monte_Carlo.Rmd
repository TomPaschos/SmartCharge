---
title: "Monte Carlo Simulation"
author: "Danny Ettelson"
date: "1/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loadlib, message= FALSE, warning= FALSE}


#load libraries
library(tidyverse)
library(dplyr)
library(RColorBrewer)


#LOAD DATA
#Price Schedule
price_schedule <- read_csv("Model_Map/2018_Summer_TOU_EV_4.csv")

#Price Schedule Options (All in Model_Map Folder)

#2018 Summer 3
#read_csv("Model_Map/2018_Summer_TOU_EV_3.csv")

#2018 Summer 4
#read_csv("Model_Map/2018_Summer_TOU_EV_4.csv")

#2018 Winter 3
#read_csv("Model_Map/2018_Winter_TOU_EV_3.csv")

#2018 Winter 4
#read_csv("Model_Map/2018_Winter_TOU_EV_4.csv")

#2018 Winter D
#read_csv("Model_Map/2018_Winter_TOU_EV_D.csv")

#2019 Summer 8
#read_csv("Model_Map/2019_Summer_TOU_EV_8.csv")

#2019 Winter 8
#read_csv("Model_Map/2019_Winter_TOU_EV_8.csv")


#Baseline Usage
#baseline <- read_csv("Model_Map/03-18_WP_Avg.csv")

DC_baseline <- read_csv("Model_Map/DC_Avg_Usage.csv")
WP_baseline <- read_csv("Model_Map/DC_Avg_Usage.csv")
MUD_baseline <- read_csv("Model_Map/DC_Avg_Usage.csv")
F_baseline <- read_csv("Model_Map/DC_Avg_Usage.csv")


baseline <- bind_rows("Destination Center" = DC_baseline, "Fleet" = F_baseline, "Multi Unit Dwelling" = MUD_baseline,"Workplace" = WP_baseline, .id = "Segment") 
  

Wokplace_Total_Usage <- read_csv("Model_Map/Wokplace_Total_Usage.csv")
Workplace_Avg_Usage <- read_csv("Model_Map/Workplace_Avg_Usage.csv")

# Number of Chargers by Segment
#chargers <- read_csv("Model_Map/Chargers_Installed_03-18.csv")
Chargers <- read_csv("Model_Map/Chargers.csv")
Event_Chargers <- read_csv("Model_Map/Event_Chargers.csv")

add_baseline_chargers <- Chargers %>% 
  filter(Market_Segment!= "Total") %>% 
  slice(rep(1:n(),each=24))

#Elasticities with format 9X3 with columns Base_Hr, Changed_Hr, and Elasticity
#Changed_Hr is the Hour where the price change occurs, Base_Hr is the hour in which demand changes
Elasticities <- read_csv("SDGE_Elasticities.csv")
SDGE_P_SOP_Ratios <- read_csv("SDGE_P_SOP_Ratios.csv")


#Ratio for selecting Default Elasticities
P_SOP_Ratio <- max(price_schedule$P0)/min(price_schedule$P0)
#Matches our closest Ratio to Inputted Ratio
closest_schedule <- SDGE_P_SOP_Ratios$Rate_Schedule[which.min(abs(SDGE_P_SOP_Ratios$P_SOP_Ratio - P_SOP_Ratio))]
closest_elasticities <- match(closest_schedule, names(Elasticities))
#Uses Elasticities of rate schedule with closest ratio


June_Sep_chargers <-Chargers %>% 
  select(Market_Segment, June_18:Aug_18)

June_Sep_baseline <- baseline %>% 
  select(Segment, Hr,  June_18:Aug_18) %>% 
  mutate(B_Jun = June_18/June_Sep_chargers$June_18)



```

```{r function}

#Set variables and values
#All defaults are set to MARCH 2018 WORKPLACE
p_c <- -0.05 #price change
i_h <- c(12:15) #intervention hours
t_a <- -0.5 #throttling amount
t_h <- c(7:11) #throttling hours
sch <- closest_elasticities #elasticities to use for price intervention (column in the elasticities dataframe) -  Non PV Summer Weekday EPEV L. The default now picks from the ratio 
tsch <- closest_elasticities  #elasticites to use for throttling intervention (column in the elasticities dataframe) - Non PV Summer Weekday EPEV L
sg <- "Workplace" #segment
mth <- "Mar_18" #month
pwr <- 6.6 #charger power
pk <- c(17:21) #target window to shift out off (this is only used in the output calculations below, not for the function)
int_ch <- filter(Chargers, Market_Segment == sg) %>% 
  select(mth) %>% 
  as.numeric() # default is to MARCH 2018
int_e_b <- TRUE
SDGE_c_e <- 0.2
i_c_e <- 0.2



hourly_demand <- function(segment = sg, month = mth, charger_power = pwr, schedule = sch, throttle_schedule = tsch,price_change = p_c,intervention_hours = i_h, intervention_chargers = int_ch, int_equals_baseline = int_e_b, throttle_amount = t_a,throttle_hours = t_h, SDGE_commm_effect = SDGE_c_e, intervention_comm_effect = i_c_e){
  
  #CONTEXT#####
  
  #This section puts the Hr, initial price (P0), period, initial unscaled load (Xi), and scaled load (XO) into EV_Demand
  
  #Price Schedule is read in above

# Elasticity 
chosen_elasticities <- Elasticities[c(1,2,schedule)] #this pulls out columns 1, 2, and the designated elasticity (from row 74 into a new dataframe) 
colnames(chosen_elasticities) <- c("Base_Hr","Changed_Hr","Elasticity")
chosen_elasticities_t <- Elasticities[c(1,2,throttle_schedule)]
colnames(chosen_elasticities_t) <- c("Base_Hr","Changed_Hr","Elasticity")

#price_schedule$period <- factor(price_schedule$period, levels = c("P","MP","OP"))

#Baseline

#filter the number of chargers by market segment and month, change to numeric (have to set the month and segment otherwise it will take the default, workplace and March 2018)
baseline_chargers <-filter(Chargers, Market_Segment == segment) %>% 
  select(month) %>% 
  as.numeric()


intervention_chargers <- ifelse(int_equals_baseline == TRUE, baseline_chargers, intervention_chargers)

#WP_Chargers <- chargers$Workplace #Number of Chargers (C)
#DC_Chargers <- chargers$Workplace #Number of Chargers (C)
baseline_month<- baseline %>% 
  filter(Segment == segment) %>% 
  select(month) %>%
  unlist()

EV_Demand <- mutate(price_schedule, I01 = 0 ,Xi = baseline_month, X0 = baseline_month/baseline_chargers*intervention_chargers) #340 here comes from the number of chargers installed for the baseline. I01 refers to the hours where there is an intervention. 

EV_Demand$I01[intervention_hours] <-1


  #MAX_THEORETICAL#### 
#Theoretical max is based on the current number of chargers in the SCE Charge Ready pilot program, multiplied by the average power rating of Level 2 EV chargers (6.6 kW), multiplied by 1 hour.  This gives us the total number of kWh for each hour that could be achieved if every charger were utilized during the target load shift window of 11 AM - 3 PM.


Max_Theory <- intervention_chargers*charger_power


####



  #SPLINING####
x <- c(1:24) #used for the 24 hours in for loops (24 elasticity columns)


#This makes a table for each hour that lists the midpoint hours that will be splined, hours as <24, rate period, and elasticity relative to the hour.


#Finds the hours in the rate schedule just before the period changes
change_points <- which(price_schedule$Period != dplyr::lag(price_schedule$Period)) - 1

#Finds the midpoints of each "chunk" of rate periods unless the "chunk" spans over the end of the day
mid_points <- change_points[-length(change_points)] +diff(change_points)/2

#finds the midpoint of the "chunk" of rate period that spans over the end of the day
rollover_midpoint <- (change_points[1]+24 + change_points[length(change_points)])/2 -24

#adds rollover_midpoint but only if there is actually a rate period "chunk" that rolls over the day
if(price_schedule$Period[1] == price_schedule$Period[length(price_schedule$Period)]) {
  mid_points <- append(mid_points, rollover_midpoint)
}
  
  #create a dataframe of the own and cross elasticities of the midpoints and self point (i.e., put the stepwise elasticities into one)
for(i in x) {
    nam <- paste("Midpoints", i, sep = ".")
    Hrs <- append(mid_points, i)
    Hrs <- Hrs[-match(price_schedule$Period[i],price_schedule$Period[mid_points])]
#The loop above selects a set of midpoints that leaves out one midpoint based on the hour that a table is being made for (it excludes the midpoint that is in the same period as the hour of the table)

    Hrs24 <- append(Hrs,i) #adds the end point (the starting hour 24 hours later)
    Hrs <- if_else(Hrs<i,Hrs+24,Hrs) %>% 
      append(i+24)
    #lists "real hours" from the starting point, adding 24 to any hours before the start point
    
    periods <- price_schedule$Period[c(Hrs24)] 
    #retrieves the rate periods of each hour listed
    
    own_period <- price_schedule$Period[i]
    #retrieves rate period of the current hour
    own_period_elasticities <- filter(chosen_elasticities, Base_Hr == own_period)
    midpoint_elasticities <- own_period_elasticities$Elasticity[match(periods, Elasticities$Changed_Hr)]

    
    assign(nam,data.frame(Hour=Hrs,Hrs24=Hrs24, Period=periods,Elasticity = midpoint_elasticities))
    #makes a data frame named after the current hour with each of the above variables
    
}

#spline the midpoint table
for (i in x) {
  current_hr <- eval(parse(text = sub("XX", i, "Midpoints.XX")))
  #calls current hours midpoint table
  
  Y = spline(x=current_hr$Hour,y=current_hr$Elasticity,xout=seq(min(current_hr$Hour),max(current_hr$Hour)))
  #splines elasticities to smoooth
  
  HR = Y$x
  
  ELAST = Y$y
  
  nam <- paste("Elasticities", i, sep = ".")
  
  assign(nam,data.frame(HR=HR,ELAST=ELAST,HR24 = if_else(HR<=24,HR,HR-24)))
  #makes a data frame with above variables: Hours, smoothed elasticities
}
####

  #MATRIX####

#creates our matrix based on the 24 smoothed elasticities for each hour.
#uses a for loop to call files rather than individually
#NOTE this matrix has each COLUMN to be used for each hour. Our excel used each ROW if trying to compare.

matrix <- data.frame(Hr = c(1:24))
for (i in x) {
  El <- eval(parse(text = sub("YY", i, "Elasticities.YY")))
  El <- El[-1,]
  El <- El[order(El$HR24),]
  matrix <- cbind(matrix, El$ELAST)
}
matrix<-matrix[,-1]
colnames(matrix) <- c(1:24)
####



  #INTERVENTION####

#price_change <- -0.05
#intervention_hours <- c(12:15)
EV_Demand <- mutate(EV_Demand, P1 = price_schedule$P0) #Copies the initial price schedule into a new column (P1) that can then be modified to reflect the intervention

EV_Demand$P1[intervention_hours] <-EV_Demand$P1[intervention_hours] + price_change #updates intervention column to implement intervention

EV_Demand <- mutate(EV_Demand, P1p = (P1-P0)/P0) #Adds percentage change in price (P1p)

X1p <- as.vector(0)
for (val in x) {
  mat <- sub("XX",val, "matrix$`XX`")
  sum_prod <- crossprod(EV_Demand$P1p,eval(parse(text = mat)))
  X1p<- append(X1p,sum_prod)
  
} #crossprod() multiplies sumproduct of the percent change in price with each column in the matrix. This is done 24 times by the for loop rather than 24 individual times

X1p <- X1p[-1] # gets rid of the first dummy entry to the variable
EV_Demand <- mutate(EV_Demand, X1p = X1p) #add percent change in demand due to price onto EV_Demand (X1p)

EV_Demand <- mutate(EV_Demand, X1 = (1+X1p)*X0) #adds new demand in kW variable (X1)

####


  #THROTTLE MATRIX####
#This makes a table for each hour that lists the midpoint hours that will be splined, hours as <24, rate period, and elasticity relative to the hour.

for(i in x) {
    nam <- paste("Midpoints", i, sep = ".")
    
    Hrs <- append(mid_points, i)
    Hrs <- Hrs[-match(price_schedule$Period[i],price_schedule$Period[mid_points])]
#The loop above selects a set of midpoints that leaves out one midpoint based on the hour that a table is being made for (it excludes the midpoint that is in the same period as the hour of the table)

    Hrs24 <- append(Hrs,i) #adds the end point (the starting hour 24 hours later)
    Hrs <- if_else(Hrs<i,Hrs+24,Hrs) %>% 
      append(i+24)
    #lists "real hours" from the starting point, adding 24 to any hours before the start point
    
    periods <- price_schedule$Period[c(Hrs24)] 
    #retrieves the rate periods of each hour listed
    
    own_period <- price_schedule$Period[i]
    #retrieves rate period of the current hour
    
    own_period_elasticities <- filter(chosen_elasticities_t, Base_Hr == own_period)
    midpoint_elasticities <- own_period_elasticities$Elasticity[match(periods, Elasticities$Changed_Hr)]

    
    assign(nam,data.frame(Hour=Hrs,Hrs24=Hrs24, Period=periods,Elasticity = midpoint_elasticities))
    #makes a data frame named after the current hour with each of the above variables
    
}

for (i in x) {
  current_hr <- eval(parse(text = sub("XX", i, "Midpoints.XX")))
  #calls current hours midpoint table
  
  Y = spline(x=current_hr$Hour,y=current_hr$Elasticity,xout=seq(min(current_hr$Hour),max(current_hr$Hour)))
  #splines elasticities to smoooth
  
  HR = Y$x
  
  ELAST = Y$y
  
  nam <- paste("Elasticities", i, sep = ".")
  
  assign(nam,data.frame(HR=HR,ELAST=ELAST,HR24 = if_else(HR<=24,HR,HR-24)))
  #makes a data frame with above variables: Hours, smoothed elasticities
}

#creates our matrix based on the 24 smoothed elasticities for each hour.
#uses a for loop to call files rather than individually
#NOTE this matrix has each COLUMN to be used for each hour. Our excel used each ROW if trying to compare.

matrixt <- data.frame(Hr = c(1:24))
for (i in x) {
  El <- eval(parse(text = sub("YY", i, "Elasticities.YY")))
  El <- El[-1,]
  El <- El[order(El$HR24),]
  matrixt <- cbind(matrixt, El$ELAST)
}
matrixt<-matrixt[,-1]
colnames(matrixt) <- c(1:24)

####


  #THROTTLING####

#throttle_amount <- 0 #throttling amount -0.5 - 50%
Tp <- rep(0,24)
#throttle_hours <- c(7:11) #hours that throttling occurs
Tp[throttle_hours] <- throttle_amount #Assigns the throttling intervention percentage chosen at the inputs at the beginning to the hours chosen then
EV_Demand <- mutate(EV_Demand, Tp=Tp) #Adds throttling percentage to each hour (Tp)

E <- as.vector(0) #dummy for self-elasticities (E)

for (val in x) {
  self <- matrixt[val,val] 
  E <- append(E,self)
} #checks the matrix for the self elasticity and adds it to a vector, repeated 24 times as a for loop rather than 24 times

E <- E[-1] #removing dummy

EV_Demand <- mutate(EV_Demand, Ptp = Tp/E, Pt = (1+Ptp)*P1)#Creates an equivalent change in price during that hour that would be required to see the drop in demand due to throttling. Note, we don't need Pt to find Xtp or Xt, but we're calculating it for our own edification when looking at the table output.  

Xtp <- as.vector(0) #Dummy for change in demand due to throttling (Xtp)

for (val in x) {
  mat <- sub("XX",val, "matrixt$`XX`")
  sum_prod <- crossprod(EV_Demand$Ptp,eval(parse(text = mat)))
  Xtp<- append(Xtp,sum_prod)
} #uses new price equivalent sumproduct with each hour's elasticities to find percent change in demand due to throttling
Xtp <- Xtp[-1] #gets rid of dummy

EV_Demand <- mutate(EV_Demand, Xtp = Xtp, Xt = (Xtp+1)*X1, MT = Max_Theory) #adds (Xtp) and the new demand in kW due to throttling (Xt). Adds the max theoretical to the end of the dataframe for our reference. 
EV_Demand$Xt <- if_else(EV_Demand$Xt >= 0, EV_Demand$Xt, 0) 


####


  #COMMUNICATION####

#The variables below quantify the shift and net change in demand as a result of interventions, and need to be adjusted based on intervention (does not count throttling)

Total_x0 <- sum(EV_Demand$X0)
Total_xt <-sum(EV_Demand$Xt)

Net_Change <- Total_xt-Total_x0
Change_intervention <- abs(sum(EV_Demand$Xt[intervention_hours]) - sum(EV_Demand$X0[intervention_hours]))
Change_outside_intervention <- abs(sum(EV_Demand$Xt[-intervention_hours])- sum(EV_Demand$X0[-intervention_hours]))


change_int_no_comm <- Change_intervention/(1+SDGE_commm_effect)
change_int_comm <- change_int_no_comm*(1+intervention_comm_effect)
comm_shifting <- change_int_comm - change_int_no_comm



EV_Demand <- mutate(EV_Demand, Xint_effect = Xt - X0, comm_shift = 0)

EV_Demand$comm_shift[intervention_hours] <-(abs(EV_Demand$Xint_effect[intervention_hours])/Change_intervention)*comm_shifting

EV_Demand$comm_shift[-intervention_hours] <- (abs(EV_Demand$Xint_effect[-intervention_hours])/Change_outside_intervention)*-comm_shifting

EV_Demand$comm_shift[is.nan(EV_Demand$comm_shift)] <- 0

EV_Demand <- mutate(EV_Demand, Xf = Xt + comm_shift)




####


return(list(EV_Demand=EV_Demand,matrix=matrix,Matrix_throttling=matrixt)) #This is how to output multiple data frames from the fcn. 

}
EV_Demand_run1 <- hourly_demand(month = "Nov_18",SDGE_commm_effect = 0,intervention_comm_effect = 0, throttle_amount = 0, price_change = 0.1, intervention_hours = c(16:18))
#EV_Demand_run1 <- hourly_demand(month = "Jul_18", int_equals_baseline = FALSE, intervention_chargers = 234) #creates a data frame with the output from the function, which is needed to find the emission factors.

```

```{r emissions_outputs}

#Load Emissions Factors
Hourly_EF <- read_csv("Hrly_EF.csv")
# Current hourly EF csv is fake. Numbers will be in lbs/kwh for both CO2 and NOX.

#Load default periods (intervention hour is set above); decide if moving these defaults above
pk <- c(17:21) #target window to shift out off (this is only used in the output calculations below, not for the function)

#Insert costs ($/kg)
NOXcost <- 21.93 #$/kg
Curtailmentcost <- 0.15 #$/MWH This number needs to be sourced and updated! 

#emissions_x <- emission_output(run_x$EV_Demand)
# emissions_x<- emission_output(hourly_demand()) 
# Emissionfcn <- function (EV_Demand_run1, peak_hour = pk) {
# add a column to output of hourly demand that specifies intervention hours (binary 1: 0; intervention hours = 1; not = 0); read that in for intervention hour; read in peak hours as another input; then calculate everything else other hour of concern (peak), and other
#}

emissions_fcn <- function(EVDemand, peak_hours = pk) {
#Create Date Frame for Emissions Outputs
Emissions <- Hourly_EF %>% 
  mutate(I01 = EVDemand$EV_Demand$I01) %>% 
  mutate(Xi = EVDemand$EV_Demand$Xi) %>% # column for initial demand at each hour not scaled
  mutate(X0 = EVDemand$EV_Demand$X0) %>% # column for initial demand at each hour scaled by chargers
  mutate(Xf = EVDemand$EV_Demand$Xf) 
     # column for new demand at each hour. we'll need to update "Xt" to reflect the new column post comms/all interventions

Emissions <- Emissions %>% 
  mutate(Xdelta = Xf - X0) #add in delta (change) row. The function could spit this out in its final data frame and then we can copy this in and add it to the code above. 

#Calculate emissions for baseline demand (scaled and not)
Emissions <- Emissions %>%
  mutate (CO2Xi = Xi*CO2Baseline) %>% 
  mutate (NOXXi = Xi*NOXBaseline) %>% 
  mutate (CO2X0 = X0*CO2Baseline) %>% 
  mutate (NOXX0 = X0*NOXBaseline)

#calculate change in emissions
Emissions <- Emissions %>%
  mutate (CO2Xdelta = Xdelta*CO2Marginal) %>% 
  mutate (NOXXdelta= Xdelta*NOXMarginal)

#calculate emissions for final
Emissions <- Emissions %>%
  mutate (CO2Xf = CO2X0+CO2Xdelta) %>% # baseline emissions - change for emissions associated with final demand
  mutate (NOXXf = NOXX0+NOXXdelta)

#Set intervention hours, peak hours, other hours based on intervention hours selected for hourly demand fcn and peak hours input above. 
#Find interventions hours
intervention_emission_hours <- which(Emissions[,6] == 1) #pulls intervention hours from initial hourly demand fcn
#Find other hours based on intervention hours set in hourly function and peak hour input
other_emission_hours <- c(1:24) #create 1:24 for all other hours
other_emission_hours <-other_emission_hours[!other_emission_hours %in% intervention_emission_hours] #remove the intervention hours
other_emission_hours <-other_emission_hours[!other_emission_hours %in% peak_hours] #remove the pk hours
  
#Sum base emissions by period (intervention window, peak window, other)
 CO2X0_i_h <- sum(Emissions$CO2X0[intervention_emission_hours]) 
 CO2X0_pk <- sum(Emissions$CO2X0[peak_hours]) 
 CO2X0_o_h <- sum(Emissions$CO2X0[other_emission_hours]) 
 CO2X0_sum <- sum(Emissions$CO2X0)
 NOXX0_i_h <- sum(Emissions$NOXX0[intervention_emission_hours])
 NOXX0_pk <- sum(Emissions$NOXX0[peak_hours])
 NOXX0_o_h <- sum(Emissions$NOXX0[other_emission_hours]) 
 NOXX0_sum <- sum(Emissions$NOXX0)
 
#Sum final emissions by period (intervention window, peak window, other)
 CO2Xf_i_h <- sum(Emissions$CO2Xf[intervention_emission_hours]) #11-3 window
 CO2Xf_pk <- sum(Emissions$CO2Xf[peak_hours]) #peak 4pm-9pm window
 CO2Xf_o_h <- sum(Emissions$CO2Xf[other_emission_hours]) #all other hours
 CO2Xf_sum <- sum(Emissions$CO2Xf)
 NOXXf_i_h <- sum(Emissions$NOXXf[intervention_emission_hours]) #11-3 window
 NOXXf_pk <- sum(Emissions$NOXXf[peak_hours]) #peak 4pm-9pm window
 NOXXf_o_h <- sum(Emissions$NOXXf[other_emission_hours]) #all other hours
 NOXXf_sum <- sum(Emissions$NOXXf)
 
#Sum change in emissions by period (intervention window, peak window, other)
 CO2Xdelta_i_h <- sum(Emissions$CO2Xdelta[intervention_emission_hours]) #11-3 window
 CO2Xdelta_pk <- sum(Emissions$CO2Xdelta[peak_hours]) #peak 4pm-9pm window
 CO2Xdelta_o_h <- sum(Emissions$CO2Xdelta[other_emission_hours]) #all other hours
 CO2Xdelta_sum <- sum(Emissions$CO2Xdelta)
 NOXXdelta_i_h <- sum(Emissions$NOXXdelta[intervention_emission_hours]) #11-3 window
 NOXXdelta_pk <- sum(Emissions$NOXXdelta[peak_hours]) #peak 4pm-9pm window
 NOXXdelta_o_h <- sum(Emissions$NOXXdelta[other_emission_hours]) #all other hours
 NOXXdelta_sum <- sum(Emissions$NOXXdelta)
 
#Put into new df
Emissions_Table <- data.frame(Time= c("intervention hours", "peak period", "other", "Total"), CO2Initial = c(CO2X0_i_h, CO2X0_pk, CO2X0_o_h, CO2X0_sum), CO2Final = c(CO2Xf_i_h, CO2Xf_pk, CO2Xf_o_h, CO2Xf_sum), CO2Change = c(CO2Xdelta_i_h, CO2Xdelta_pk, CO2Xdelta_o_h, CO2Xdelta_sum), NOXInitial = c(NOXX0_i_h, NOXX0_pk, NOXX0_o_h, NOXX0_sum), NOXFinal = c(NOXXf_i_h, NOXXf_pk, NOXXf_o_h, NOXXf_sum), NOXChange = c(NOXXdelta_i_h, NOXXdelta_pk, NOXXdelta_o_h, NOXXdelta_sum))
#Note: there's got to be a cleaner way to calculate these totals.  

#Calculate cost reduction from NOX reduction (only doing it for the change)
Emissions_Table <- Emissions_Table %>% 
   mutate(NOXChangeCost = NOXChange*NOXcost) #this is in dollars

#Curtailment Cost Reduction
#sum hours of demand change in target window
Xdelta_i_h <- sum(Emissions$Xdelta[intervention_emission_hours])
Curtailmentcost_i_h <- Xdelta_i_h*-Curtailmentcost
#add to output table
Emissions_Table <- Emissions_Table %>% 
   mutate(ChangeCurtCost = c(Curtailmentcost_i_h, "NA", "NA", Curtailmentcost_i_h))

return(list(Emissions=Emissions, Emissions_Table=Emissions_Table))
  
}
#Emissions_run1 <- emissions_fcn(EVDemand = hourly_demand(SDGE_commm_effect = 0,intervention_comm_effect = 0, throttle_amount = 0)) #or run as emissions_fcn(EV_Demand_run1)

```


```{r simulation}


simulation <- function(simulations = 100, hourlydemand = hourly_demand()) {
  
  intervention_draws <- sample(3:length(Elasticities),simulations,replace = TRUE)
  throttle_draws <- sample(3:length(Elasticities),simulations,replace = TRUE)
  comm_possibilities <- seq(from=0, to=0.5, by=.01)
  comm_draws <-  sample(comm_possibilities,simulations, replace = TRUE)

  sim_result <- hourlydemand
  sim_result_EV_Demand <- mutate(sim_result$EV_Demand, i_draw = intervention_draws[1], t_draw =     throttle_draws[1])
  sim_result_EV_Demand <- sim_result_EV_Demand[0,]


  for(i in seq(simulations)){
    run_i <- hourly_demand(schedule = intervention_draws[i],throttle_schedule = throttle_draws[i], intervention_comm_effect = comm_draws[i], month = "Nov_18", throttle_amount = 0)
    run_i_EV_Demand <- run_i$EV_Demand %>% 
      mutate(i_draw = intervention_draws[i], t_draw = throttle_draws[i])
  
    sim_result_EV_Demand <- rbind(sim_result_EV_Demand,run_i_EV_Demand)
  
  
  }

    summary <- group_by(sim_result_EV_Demand, Hr) %>% 
    summarise_at(vars(Xf),funs(mean,min,max))# %>% 


  sim_result_EV_Demand <- sim_result_EV_Demand %>% 
    mutate(Hr_avg = summary_test$mean[Hr], min = summary_test$min[Hr], max = summary_test$max[Hr])
  
}


#sim1 <- simulation()


```


```{r explore}



# plot of monte carlo output
library(ggplot2)
freq_graph <- ggplot(sim1, aes(x = Hr, y = X0))+
  geom_jitter(aes(y = Xf, color = Xf>X0), alpha = 0.5, width = 0.3) +
  geom_line(aes(x = Hr, y = X0), alpha = 0.5, color = "blue")+
  geom_point(aes(x = Hr, y = X0), alpha = 0.5, color = "blue")+
  #geom_ribbon(aes(ymin = min, ymax = max), alpha = 0.5, color ="blue") +
  #geom_line(aes(x = Hr, y = Hr_avg), alpha = 0.5, color = "red")+
  #geom_smooth(model = "lm") +
  theme_minimal() +
  xlab("Hour of the Day") +
  ylab("Charging Demand (kW)") +
  ggtitle("Monte Carlo Simulation of Charging Demand Per Hour")

freq_graph
```


```{r figures}

#need to stack both demand curves in one data frame for a legend
EV_Demand_run1 <- hourly_demand(month = "Nov_18",SDGE_commm_effect = 0,intervention_comm_effect = 0, throttle_amount = 0,throttle_hours = c(8:11), price_change = -0.05, intervention_hours = c(12:15))

graph_table <- EV_Demand_run1$EV_Demand[c("Hr","X0","Xf")] %>% 
  gather(condition,value,X0:Xf) %>% 
  mutate(Theoretical_Max=EV_Demand_run1$EV_Demand$MT[1])


Demand_Graph <- ggplot(data = graph_table, aes(x = Hr)) +
  geom_line(aes(y = value, color=condition)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  labs(title="Hourly Demand Forecast", 
       subtitle="$0.05 Discount 11 AM - 3 PM",
       y="EV Charging Demand (kW)",
       x="Hour",
       color=NULL) +
  scale_x_continuous(breaks = 1:24, limits = c(1,24), expand = c(0, 0)) +
  scale_color_manual(labels=c("Baseline Demand","Demand with Intervention"), values = c("blue", "red")) +
  #geom_rect(aes(xmin=6,xmax=11,ymin=-Inf,ymax=Inf,fill="Throttle"),alpha=0.0075) +
  geom_rect(aes(xmin=11,xmax=15,ymin=-Inf,ymax=Inf, fill = "Discount"),alpha=0.0075) +
  #theme_bw() + # theme_bw() gives grid lines, could remove
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(plot.subtitle = element_text(hjust = 0.5))+
 theme(legend.position="bottom") +
  scale_fill_manual('Interventions',values = c('green','yellow'),  guide = guide_legend(override.aes = list(alpha = 0.15)))

Potential_Graph <- Demand_Graph +
  geom_segment(aes(y=Theoretical_Max, yend=Theoretical_Max, x=11, xend=15))
  
# \n 50% Throttling 6 AM - 11 AM label for throttling
# Aesthetic Notes:
# might try to remove space b/w Y-axis and hr0, as well as past hr24
# bold axis titles
# color brewer
# geom_line(aes(y=Theoretical_Max, x=11:15)) +

# If we want to graph the Max Theoretical Segment, we can use this:
# geom_segment(aes(y=Theoretical_Max, yend=Theoretical_Max, x=11, xend=15))


Demand_Graph
Potential_Graph


```

```{r hypothetical_scenarios}

Total_max_theory <- pwr*Chargers$Nov_18[5]
Workplace_max_theory <- pwr*Chargers$Nov_18[4]
MUD_max_theory <- pwr*Chargers$Nov_18[3]
Fleet_max_theory <- pwr*Chargers$Nov_18[2]
DC_max_theory <- pwr*Chargers$Nov_18[1]

Max_theory_table <- Chargers %>% 
  select(Market_Segment, Nov_18) %>% 
  mutate(Theoretical_Max = pwr*Nov_18)

Max_theory_table #This shows the theoretical max per market segment (and total) for the SCE Charge Ready Pilot for ONE hour.

```


```{r pilot data}

Workplace_chargers <- filter(Chargers, Market_Segment == "Workplace") %>% 
  select(Jul_18, Jul_18, Aug_18, Sep_18) 

Workplace_Event_Chargers<-filter(Event_Chargers, Market_Segment == "Workplace")

WP_Avg_Usage_PerPort<- Workplace_Avg_Usage$Jul_18/Workplace_chargers
Scale_Jul_11_18 <- WP_Avg_Usage_PerPort*Workplace_Event_Chargers

July_WP_Table <- mutate(Scale_Jul_11_18)

View(WP_Avg_Usage_PerPort)




```

